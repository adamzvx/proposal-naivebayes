{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Naive Bayes Adam S.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "toD3sEUxNlfr"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMA/A94pGtC4DPQFqqHqRXN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aF4WTpJnQi6h"
      },
      "source": [
        "# adam [](https://towardsdatascience.com/na%C3%AFve-bayes-from-scratch-using-python-only-no-fancy-frameworks-a1904b37222d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "toD3sEUxNlfr"
      },
      "source": [
        "## paproces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OozuDnl_wY6"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "import re"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkKGQlMDKsSc",
        "outputId": "90f95fdb-9604-4d30-fef5-f66c9f835f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!pip install Sastrawi\n",
        "from Sastrawi.StopWordRemover.StopWordRemoverFactory import StopWordRemoverFactory\n",
        "\n",
        "\n",
        "def hapuskurung(text):\n",
        "  return re.sub('\\[[^]]*\\]', '', text)\n",
        "\n",
        "def hapusurl(text):\n",
        "  return re.sub(r'http\\S+', '', text)\n",
        "\n",
        "def hapus_spec_cha(text):\n",
        "  pattern = r'[^a-zA-z0-9\\s]'\n",
        "  text = re.sub(pattern, '', text)\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "stops = StopWordRemoverFactory()\n",
        "stop = stops.get_stop_words()\n",
        "# print(stop)\n",
        "\n",
        "#stopword\n",
        "def hapusstopwordSaswi(text):\n",
        "  twtext = []\n",
        "  for i in text.split():\n",
        "    if i.strip().lower() not in stop and i.strip().lower().isalpha():\n",
        "      twtext.append(i.strip().lower())\n",
        "  return \" \".join(twtext)\n",
        "\n",
        "def clean(text):\n",
        "  text = hapuskurung(text)\n",
        "  text = hapusurl(text)\n",
        "  text = hapus_spec_cha(text)\n",
        "  text = hapusstopwordSaswi(text)\n",
        "  return text\n",
        "\n",
        "def preprocess_string(str_arg):\n",
        "    cleaned_str=re.sub('[^a-z0-9\\s]+',' ',str_arg,flags=re.IGNORECASE) #every char except alphabets is replaced\n",
        "    cleaned_str=re.sub('(\\s+)',' ',cleaned_str) #multiple spaces are replaced by single space\n",
        "    cleaned_str=cleaned_str.lower() #converting the cleaned string to lower case\n",
        "    \n",
        "    return cleaned_str # returning the preprocessed string \n",
        "    print(cleaned_str)\n",
        "\n",
        "# df_tweet['text'] = df_tweet['text'].apply(clean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Sastrawi\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4b/bab676953da3103003730b8fcdfadbdd20f333d4add10af949dd5c51e6ed/Sastrawi-1.0.1-py2.py3-none-any.whl (209kB)\n",
            "\r\u001b[K     |█▋                              | 10kB 17.7MB/s eta 0:00:01\r\u001b[K     |███▏                            | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▊                           | 30kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████                     | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 215kB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: Sastrawi\n",
            "Successfully installed Sastrawi-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqWpNfQ8LZqc"
      },
      "source": [
        "## Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TqsDQse0LakK"
      },
      "source": [
        "class NaiveBayes:\n",
        "    \n",
        "    def __init__(self,unique_classes):\n",
        "        \n",
        "        self.classes=unique_classes # Constructor is sinply passed with unique number of classes of the training set\n",
        "        \n",
        "\n",
        "    def addToBow(self,example,dict_index):\n",
        "        \n",
        "        \n",
        "        if isinstance(example,np.ndarray): example=example[0]\n",
        "     \n",
        "        for token_word in example.split(): #for every word in preprocessed example\n",
        "          \n",
        "            self.bow_dicts[dict_index][token_word]+=1 #increment in its count\n",
        "            \n",
        "    def train(self,dataset,labels):\n",
        "        \n",
        "    \n",
        "        self.examples=dataset\n",
        "        self.labels=labels\n",
        "        self.bow_dicts=np.array([defaultdict(lambda:0) for index in range(self.classes.shape[0])])\n",
        "        \n",
        "        #only convert to numpy arrays if initially not passed as numpy arrays - else its a useless recomputation\n",
        "        \n",
        "        if not isinstance(self.examples,np.ndarray): self.examples=np.array(self.examples)\n",
        "        if not isinstance(self.labels,np.ndarray): self.labels=np.array(self.labels)\n",
        "            \n",
        "        #constructing BoW for each category\n",
        "        for cat_index,cat in enumerate(self.classes):\n",
        "          \n",
        "            all_cat_examples=self.examples[self.labels==cat] #filter all examples of category == cat\n",
        "            \n",
        "            #get examples preprocessed\n",
        "            \n",
        "            cleaned_examples=[preprocess_string(cat_example) for cat_example in all_cat_examples]\n",
        "            \n",
        "            cleaned_examples=pd.DataFrame(data=cleaned_examples)\n",
        "            \n",
        "            #now costruct BoW of this particular category\n",
        "            np.apply_along_axis(self.addToBow,1,cleaned_examples,cat_index)\n",
        "      \n",
        "        prob_classes=np.empty(self.classes.shape[0])\n",
        "        all_words=[]\n",
        "        cat_word_counts=np.empty(self.classes.shape[0])\n",
        "        for cat_index,cat in enumerate(self.classes):\n",
        "           \n",
        "            #Calculating prior probability p(c) for each class\n",
        "            prob_classes[cat_index]=np.sum(self.labels==cat)/float(self.labels.shape[0]) \n",
        "            \n",
        "            #Calculating total counts of all the words of each class \n",
        "            count=list(self.bow_dicts[cat_index].values())\n",
        "            cat_word_counts[cat_index]=np.sum(np.array(list(self.bow_dicts[cat_index].values())))+1 # |v| is remaining to be added\n",
        "            \n",
        "            #get all words of this category                                \n",
        "            all_words+=self.bow_dicts[cat_index].keys()\n",
        "                                                     \n",
        "        \n",
        "        #combine all words of every category & make them unique to get vocabulary -V- of entire training set\n",
        "        \n",
        "        self.vocab=np.unique(np.array(all_words))\n",
        "        self.vocab_length=self.vocab.shape[0]\n",
        "                                  \n",
        "        #computing denominator value                                      \n",
        "        denoms=np.array([cat_word_counts[cat_index]+self.vocab_length+1 for cat_index,cat in enumerate(self.classes)])                                                                          \n",
        "      \n",
        "        self.cats_info=[(self.bow_dicts[cat_index],prob_classes[cat_index],denoms[cat_index]) for cat_index,cat in enumerate(self.classes)]                               \n",
        "        self.cats_info=np.array(self.cats_info)                                 \n",
        "                                              \n",
        "                                              \n",
        "    def getExampleProb(self,test_example):                                                               \n",
        "                                              \n",
        "        likelihood_prob=np.zeros(self.classes.shape[0]) #to store probability w.r.t each class\n",
        "        \n",
        "        #finding probability w.r.t each class of the given test example\n",
        "        for cat_index,cat in enumerate(self.classes): \n",
        "                             \n",
        "            for test_token in test_example.split(): #split the test example and get p of each test word\n",
        "                \n",
        "                ####################################################################################\n",
        "                                              \n",
        "                # for each word w [ count(w|c)+1 ] / [ count(c) + |V| + 1 ]                               \n",
        "                                              \n",
        "                ####################################################################################                              \n",
        "                \n",
        "                #get total count of this test token from it's respective training dict to get numerator value                           \n",
        "                test_token_counts=self.cats_info[cat_index][0].get(test_token,0)+1\n",
        "                \n",
        "                #now get likelihood of this test_token word                              \n",
        "                test_token_prob=test_token_counts/float(self.cats_info[cat_index][2])                              \n",
        "                \n",
        "                #remember why taking log? To prevent underflow!\n",
        "                likelihood_prob[cat_index]+=np.log(test_token_prob)\n",
        "                                              \n",
        "        # we have likelihood estimate of the given example against every class but we need posterior probility\n",
        "        post_prob=np.empty(self.classes.shape[0])\n",
        "        for cat_index,cat in enumerate(self.classes):\n",
        "            post_prob[cat_index]=likelihood_prob[cat_index]+np.log(self.cats_info[cat_index][1])                                  \n",
        "      \n",
        "        return post_prob\n",
        "    \n",
        "   \n",
        "    def test(self,test_set):\n",
        "       \n",
        "        predictions=[] #to store prediction of each test example\n",
        "        for example in test_set: \n",
        "                                              \n",
        "            #preprocess the test example the same way we did for training set exampels                                  \n",
        "            cleaned_example=preprocess_string(example) \n",
        "             \n",
        "            #simply get the posterior probability of every example                                  \n",
        "            post_prob=self.getExampleProb(cleaned_example) #get prob of this example for both classes\n",
        "            \n",
        "            #simply pick the max value and map against self.classes!\n",
        "            predictions.append(self.classes[np.argmax(post_prob)])\n",
        "        \n",
        "        return np.array(predictions)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XI9Ar61BLv1T",
        "outputId": "f3cbd204-523e-4bb7-8415-07f28ba560b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "training_set=pd.read_csv('data-tweet-fin-c.csv') # reading the training data-set\n",
        "type(training_set)\n",
        "training_set.head()\n",
        "\n",
        "#getting training set examples labels\n",
        "y_train=training_set['label'].values\n",
        "x_train=training_set['text'].values\n",
        "\n",
        "# tes data set\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_data,test_data,train_labels,test_labels=train_test_split(x_train,y_train,shuffle=True,test_size=0.01,random_state=42,stratify=y_train)\n",
        "# classes=np.unique(train_labels)\n",
        "\n",
        "# Training phase....\n",
        "nb=NaiveBayes(classes)\n",
        "nb.train(train_data,train_labels)\n",
        "\n",
        "# Testing \n",
        "testkatanya = [\n",
        "               \"tok inglish mengajarkan istrinya istri tak belajar agama gimana mengajarkan mengajarkan istrinya istri tak belajar agama gimana mengajarkan\",\n",
        "               \"aduh bang jago\",\n",
        "               \"Allaah bersama orang yang sabar\",\n",
        "               \"Ada yang tahu penulisan yang benar itu dimana atau di mana\",\n",
        "               \"Tak jarang kata-kata memiliki peran yang cukup besar untuk membangkitkan semangat seseorang ketika sedang merasa tidak baik-baik saja\",\n",
        "               ]\n",
        "nptestkatanya = np.array(testkatanya)\n",
        "\n",
        "pclasses=nb.test(nptestkatanya)\n",
        "# print(test_data)\n",
        "print(nptestkatanya)\n",
        "print(pclasses)\n",
        "\n",
        "\n",
        "for i in range(len(pclasses)):\n",
        "  if pclasses[i]==0:\n",
        "    x='tidak terindikasi'\n",
        "  else:\n",
        "    x='terindikasi'\n",
        "  print(nptestkatanya[i], '-', x)\n",
        "\n",
        "# test_akurasi=np.sum(pclasses==test_labels)/float(test_labels.shape[0])\n",
        "\n",
        "# print (\"Test Set Akurasi: \",test_akurasi) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['tok inglish mengajarkan istrinya istri tak belajar agama gimana mengajarkan mengajarkan istrinya istri tak belajar agama gimana mengajarkan'\n",
            " 'aduh bang jago' 'Allaah bersama orang yang sabar'\n",
            " 'Ada yang tahu penulisan yang benar itu dimana atau di mana'\n",
            " 'Tak jarang kata-kata memiliki peran yang cukup besar untuk membangkitkan semangat seseorang ketika sedang merasa tidak baik-baik saja']\n",
            "[0 1 0 0 0]\n",
            "tok inglish mengajarkan istrinya istri tak belajar agama gimana mengajarkan mengajarkan istrinya istri tak belajar agama gimana mengajarkan - tidak terindikasi\n",
            "aduh bang jago - terindikasi\n",
            "Allaah bersama orang yang sabar - tidak terindikasi\n",
            "Ada yang tahu penulisan yang benar itu dimana atau di mana - tidak terindikasi\n",
            "Tak jarang kata-kata memiliki peran yang cukup besar untuk membangkitkan semangat seseorang ketika sedang merasa tidak baik-baik saja - tidak terindikasi\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O6zehLcBL0-1",
        "outputId": "dbe1b0c7-eb2e-462c-f356-0672c4056fc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        }
      },
      "source": [
        "!pip install tweepy\n",
        "import tweepy as tw"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy) (2.23.0)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.7.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy) (1.15.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kytR3xwSMwZl",
        "outputId": "b5d42598-546b-46d6-b96e-6d4d22f8471f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "CONSUMER_key= 'xxxxxxx'\n",
        "CONSUMER_secret= 'xxxxxxx'\n",
        "ACCESS_token= 'xxxxxx'\n",
        "ACCESS_token_secret= 'xxxxxx'\n",
        "\n",
        "auth = tw.OAuthHandler(CONSUMER_key, CONSUMER_secret)\n",
        "auth.set_access_token(ACCESS_token, ACCESS_token_secret)\n",
        "api = tw.API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "\n",
        "\n",
        "cari_katanya = \"hukum buatan manusia\"\n",
        "\n",
        "# tweets = tw.Cursor(api.search,\n",
        "#               q=search_words,\n",
        "#               lang=\"en\",\n",
        "#               since=date_since).items(5)\n",
        "\n",
        "tweets_katanya = tw.Cursor(api.search,\n",
        "                           q=cari_katanya,).items(30)\n",
        "\n",
        "tweets_katanya =[tweet.text for tweet in tweets_katanya] #list\n",
        "tweets_katanya_c = list(map(clean, tweets_katanya))\n",
        "\n",
        "print(tweets_katanya)\n",
        "\n",
        "nptestkatanya = np.array(tweets_katanya_c)\n",
        "npkatanyaori  = np.array(tweets_katanya)\n",
        "\n",
        "pclasses=nb.test(nptestkatanya)\n",
        "# print(test_data)\n",
        "# print(nptestkatanya)\n",
        "# print(pclasses)\n",
        "\n",
        "for i in range(len(pclasses)):\n",
        "  if pclasses[i]==0:\n",
        "    x='tidak terindikasi'\n",
        "  else:\n",
        "    x='terindikasi'\n",
        "  print(npkatanyaori[i], '-', x)\n",
        "print(pclasses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['RT @AlmayraGucciano: Ketika mata diminta untuk tidak melihat \\nKuping tidak untuk mendengar \\nMulut tidak untuk bicara \\nTangan tidak untuk me…', 'Ketika mata diminta untuk tidak melihat \\nKuping tidak untuk mendengar \\nMulut tidak untuk bicara \\nTangan tidak untuk… https://t.co/HatkKS3Mw3', 'Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diuba… https://t.co/vxJuek2Hd0', 'Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diuba… https://t.co/PEh02Tibaf', 'RT @hilalludin26gm2: *\"Keadilan Hanya pada Hukum Allah\"*\\n\\nMendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bolong…', 'Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diuba… https://t.co/QVblyVujPc', 'RT @Lub4b1: *\"Keadilan Hanya pada Hukum Allah\"*\\n\\nMendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bolong. Maka wa…', 'Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diuba… https://t.co/t1yYQ4YgCn', 'Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diuba… https://t.co/e8auXgXb9c', 'Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diuba… https://t.co/cKa9VRybVJ', 'Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim? Hukum buatan manusia memang bebas diuba… https://t.co/iVX8gfPsm5', 'RT @Lub4b1: *\"Keadilan Hanya pada Hukum Allah\"*\\n\\nMendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bolong. Maka wa…', '*\"Keadilan Hanya pada Hukum Allah\"*\\n\\nMendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bol… https://t.co/R6movrZuI4', '*\"Keadilan Hanya pada Hukum Allah\"*\\n\\nMendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bol… https://t.co/49mqRPpkpD', '*\"Keadilan Hanya pada Hukum Allah\"*\\n\\nMendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bol… https://t.co/AssqE4NPDL', 'RT @iwanjanuarcom: Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diubah ses…', 'RT @iwanjanuarcom: Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\\nHukum buatan manusia memang bebas diubah ses…', 'RT @AbuShofy6: Hukum itu :\\n1. Dari Sang Pencipta (Pasti Benar)\\n2. Buatan manusia (Relatif)\\n\\n#jaksagakadaakhlak https://t.co/PcLwr88qPG', 'RT @AbuShofy6: Hukum itu :\\n1. Dari Sang Pencipta (Pasti Benar)\\n2. Buatan manusia (Relatif)\\n\\n#jaksagakadaakhlak https://t.co/PcLwr88qPG', 'RT @AbuShofy6: Hukum itu :\\n1. Dari Sang Pencipta (Pasti Benar)\\n2. Buatan manusia (Relatif)\\n\\n#jaksagakadaakhlak https://t.co/PcLwr88qPG', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…', 'Hukum itu :\\n1. Dari Sang Pencipta (Pasti Benar)\\n2. Buatan manusia (Relatif)\\n\\n#jaksagakadaakhlak https://t.co/PcLwr88qPG', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…', 'Hancurnya sebuah negeri jika menggunakan hukum buatan manusia.\\n#DemokrasiBukanAjaranIslam \\n#LucunyaHukumNegeri62 https://t.co/2bT1sFBkSV', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…', 'RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\\nApakah tahanan lain dapat kesempatan sama?\\nBeginilah hukum buatan manusia di alam…']\n",
            "RT @AlmayraGucciano: Ketika mata diminta untuk tidak melihat \n",
            "Kuping tidak untuk mendengar \n",
            "Mulut tidak untuk bicara \n",
            "Tangan tidak untuk me… - tidak terindikasi\n",
            "Ketika mata diminta untuk tidak melihat \n",
            "Kuping tidak untuk mendengar \n",
            "Mulut tidak untuk bicara \n",
            "Tangan tidak untuk… https://t.co/HatkKS3Mw3 - tidak terindikasi\n",
            "Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diuba… https://t.co/vxJuek2Hd0 - terindikasi\n",
            "Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diuba… https://t.co/PEh02Tibaf - terindikasi\n",
            "RT @hilalludin26gm2: *\"Keadilan Hanya pada Hukum Allah\"*\n",
            "\n",
            "Mendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bolong… - terindikasi\n",
            "Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diuba… https://t.co/QVblyVujPc - terindikasi\n",
            "RT @Lub4b1: *\"Keadilan Hanya pada Hukum Allah\"*\n",
            "\n",
            "Mendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bolong. Maka wa… - terindikasi\n",
            "Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diuba… https://t.co/t1yYQ4YgCn - terindikasi\n",
            "Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diuba… https://t.co/e8auXgXb9c - terindikasi\n",
            "Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diuba… https://t.co/cKa9VRybVJ - terindikasi\n",
            "Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim? Hukum buatan manusia memang bebas diuba… https://t.co/iVX8gfPsm5 - terindikasi\n",
            "RT @Lub4b1: *\"Keadilan Hanya pada Hukum Allah\"*\n",
            "\n",
            "Mendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bolong. Maka wa… - terindikasi\n",
            "*\"Keadilan Hanya pada Hukum Allah\"*\n",
            "\n",
            "Mendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bol… https://t.co/R6movrZuI4 - terindikasi\n",
            "*\"Keadilan Hanya pada Hukum Allah\"*\n",
            "\n",
            "Mendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bol… https://t.co/49mqRPpkpD - terindikasi\n",
            "*\"Keadilan Hanya pada Hukum Allah\"*\n",
            "\n",
            "Mendamba keadilan pada hukum buatan manusia bak mendamba rembulan di siang bol… https://t.co/AssqE4NPDL - terindikasi\n",
            "RT @iwanjanuarcom: Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diubah ses… - terindikasi\n",
            "RT @iwanjanuarcom: Apa yang bakal dijawab di hari akhir nanti bila ini ditanya Allah al-Hakim?\n",
            "Hukum buatan manusia memang bebas diubah ses… - terindikasi\n",
            "RT @AbuShofy6: Hukum itu :\n",
            "1. Dari Sang Pencipta (Pasti Benar)\n",
            "2. Buatan manusia (Relatif)\n",
            "\n",
            "#jaksagakadaakhlak https://t.co/PcLwr88qPG - terindikasi\n",
            "RT @AbuShofy6: Hukum itu :\n",
            "1. Dari Sang Pencipta (Pasti Benar)\n",
            "2. Buatan manusia (Relatif)\n",
            "\n",
            "#jaksagakadaakhlak https://t.co/PcLwr88qPG - terindikasi\n",
            "RT @AbuShofy6: Hukum itu :\n",
            "1. Dari Sang Pencipta (Pasti Benar)\n",
            "2. Buatan manusia (Relatif)\n",
            "\n",
            "#jaksagakadaakhlak https://t.co/PcLwr88qPG - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "Hukum itu :\n",
            "1. Dari Sang Pencipta (Pasti Benar)\n",
            "2. Buatan manusia (Relatif)\n",
            "\n",
            "#jaksagakadaakhlak https://t.co/PcLwr88qPG - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "Hancurnya sebuah negeri jika menggunakan hukum buatan manusia.\n",
            "#DemokrasiBukanAjaranIslam \n",
            "#LucunyaHukumNegeri62 https://t.co/2bT1sFBkSV - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "RT @mdnris_alp: Silakan berpuas diri dengan sikap kalian.\n",
            "Apakah tahanan lain dapat kesempatan sama?\n",
            "Beginilah hukum buatan manusia di alam… - terindikasi\n",
            "[0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
